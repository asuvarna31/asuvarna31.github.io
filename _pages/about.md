---
permalink: /
title: "Hi There!"
excerpt: "Ashima Suvarna"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

This is Ashima, an incoming Phd student (Fall 2024) at UCLA CS advised by [Prof. Saadia Gabriel](https://saadia-gabriel.github.io/). I was a [Deepmind Scholar](https://deepmind.google/about/education/) at the University of California, Los Angeles during my MSCS. I also collaborate with [Prof. Nanyun Peng](https://vnpeng.net/) at UCLA NLP. 

My research agenda centers on building equitable and socially responsible AI. As humans interact with AI systems, it is imperative to ensure that these models are safe, inclusive and fair. My research achieves this by focusing on a) **fair detection of toxicity and harmful behaviors** and b) **revisiting preference acquisition protocols for robust LLM alignment**. 

In the past, I have spent some amazing time interning at Walmart Labs (Summer 2022), University of New Brunswick as a Mitacs Scholar (Summer 2019) and IBM Research India (2018).

**Open Office Hours :** If you‚Äôd like to chat about research, grad school applications or feedback on essays, please fill out this [form](https://forms.gle/RqpiK85fBZAQ6U4YA).
 
<br/>


News
======
---
üçÑ **September 2024** Joining [MARS Lab](https://saadiagabriel.com/mars_lab.html) with [Genglin Liu](https://genglinliu.github.io/cv/), [Salman Rahman](https://www.linkedin.com/in/salman-rahman-853436166/) and [Sheriff Issaka](https://sheriffissaka.com/). 

üçÑ **August 2024** [Zero-Shot Event Detection](https://arxiv.org/pdf/2403.02586) was presented at ACL 2024!

üçÑ **July 2024** [DOVE](https://arxiv.org/abs/2404.00530) was presented in DMLR@ICML 2024.

<br/>

Service
======
---

- **Programme Committee / Reviewer:** ACL-SRW 2023, NAACL-SRW 2023, ICLR Tiny Papers 2023, NAACL-SRW 2024 <br/>

- **Rewards Committee:** SoCal NLP Symposium 2023 <br/>


<br/>
---
<br/>








<!-- For more info
======
- My publications can be found [here](/publications).
- My contact information can be found [here](/contact). -->


 
